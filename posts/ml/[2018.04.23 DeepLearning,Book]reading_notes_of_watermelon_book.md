# 《机器学习》西瓜书阅读笔记

## 第 1 章 绪论

### 基本术语

`机器学习`：在计算机上从`数据`（data）中产生`模型`（model）的算法，即`学习算法`（learning algorithm）。

A computer program is said to learn from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, if its performance at tasks in $T$, as measured by $P$, improves with experience $E$.

一般地，令 $D = \left \{ \vec{x_1}, \vec{x_2}, \cdots, \vec{x_m} \right \}$ 表示包含 $m$ 个`样本`（sample）的数据集，每个示例由 $d$ 个`属性`（attribute）描述，则每个样本 $\vec{x_i} = \left \{x_{i1}; x_{i2}; \cdots; x_{id} \right \}$ 是 $d$ 维样本空间 $\mathcal{X}$ 中的一个向量，$\vec{x_i} \in \mathcal{X}$，其中 $x_{ij}$ 是 $\vec{x_i}$ 在第 $j$ 个属性上的取值，$d$ 称为样本 $\vec{x_i}$ 的`维数`（dimensionality）。

属性张成的空间称为`样本空间`（sample space），每个样本都可在这个空间中找到唯一的坐标位置，因此也把一个样本称为一个`特征向量`（feature vector）。

从数据中学得模型的过程称之为`学习`（learning）或`训练`（training），学得模型适用于新样本的能力称为`泛化`（generalization）能力。

### 假设空间

`归纳`（induction）与`演绎`（deduction）是科学推理的两大基本手段。前者是从特殊到一般的泛化（generalization）过程，后者是从一般到特殊的特化（specialization）过程。从样例中学习是一个归纳的过程，亦称`归纳学习`（inductive learning）。

狭义的归纳学习是从数据中学得`概念`（concept），最基本的概念学习是布尔概念学习。可以把学习的过程看作一个在所有`假设`（hypothesis）组成的空间中进行搜索的过程，搜索目标是找到与训练集`匹配`（fit）的假设。

假设的表示一旦确定，`假设空间`（hypothesis space）及其规模大小就确定了。现实问题中通常面临很大的假设空间，但样本训练集是有限的，因此可能有多个假设与训练集一致，即存在一个与训练集一致的假设集合，称之为`版本空间`（version space）。

### 归纳偏好

机器学习算法在学习过程中对某种类型假设的偏好，称为`归纳偏好`（inductive bias）。归纳偏好可看作是学习算法在庞大的假设空间中对假设进行选择的价值观。

`奥卡姆剃刀`（Occam's Razor）是自然科学研究中常用的原则，即若存在多个假设与观察一致，则选最简单的那个。如无必要，勿增实体。

但奥卡姆剃刀原则并不平凡，“简单”的评价标准无法量化。事实上归纳偏好对应了学习算法本身所做出的关于“什么样的模型更好”的假设。`没有免费的午餐定理`（No Free Lunch Theorem，NFL）证明了在真实目标函数 $f$ 均匀分布的情况下，所有学习算法学得的模型期望性能是一致的。

脱离实际问题，空谈“什么学习算法更好”毫无意义。

## 第 2 章 模型评估与选择

### 经验误差与过拟合

学习器的实际输出与样本的真实输出之间的差异称为`误差`（error），训练集上的误差称为`训练误差`（training error），新样本上的误差称为`泛化误差`（generalization error）。

为了使泛化误差最小化，应该从训练样本中尽可能学出适用于所有潜在样本的“普遍规律”。而将训练样本的特点当作了所有潜在样本的一般性质，导致泛化性能下降的现象，称为`过拟合`（overfitting），相对地没有充分习得训练样本的一般性质的现象，称为`欠拟合`（underfitting）。

现实任务中，存在多种学习算法、不同参数配置，产生不同的模型，需要选择其中合适的模型，该问题称为`模型选择`（model selection）问题。理想状态下使用泛化误差作为模型选择的评价标准，但泛化误差无法直接获得。

### 评估方法

通常使用`测试集`（testing set）来测试学习器对新样本的判别能力，以测试集上的`测试误差`（testing error）作为泛化误差的近似。通常假设测试样本是从样本真实分布中独立同分布采样而得。

对于包含 $m$ 个样本的数据集 $D = \left \{ (\vec{x_1}, y_1), (\vec{x_2}, y_2), \cdots, (\vec{x_m}, y_m) \right \}$，需要将其分解为训练集 $S$、验证集 $V$ 和测试集 $T$，常用的方法有留出法、交叉验证法和`自助法`（bootstrapping）。

自助法即从数据集中进行 $m$ 次可重复采样，可以选出约 36.8% 的样本作为测试集，在数据集较小时较为有效。

机器学习常涉及两类参数：一是算法的参数，称为`超参数`（hyper parameter），一是模型的参数。对超参数进行设定调优的过程称为`调参`（parameter tuning）。通常使用验证集进行模型选择和调参，使用测试集评估模型的泛化能力。

### 性能度量

性能度量（performance measure），即为模型泛化能力的评价标准。给定数据集 $D = \left \{ (\vec{x_1}, y_1), (\vec{x_2}, y_2), \cdots, (\vec{x_m}, y_m) \right \}$，其中 $y_i$ 是样本 $\vec x_i$ 的真实标记。

回归任务常用的性能度量是`均方误差`（mean squared error）：
$$
E(f; \mathcal{D}) = \int_{\vec x \sim \mathcal D} (f(\vec x) - y)^2 p(\vec {x}) d\vec x
$$

分类任务常用的性能度量较多，常用的错误率：
$$
E(f; \mathcal{D}) = \int_{\vec x \sim \mathcal D} \mathbb I(f(\vec x) \neq y) p(\vec {x}) d\vec x
$$
`准确率`（percision）和`召回率`（recall）：
$$
\begin{aligned}
P &= \frac {TP} {TP + FP} \\
R &= \frac {TP} {TP + FN}
\end{aligned}
$$

|          | 预测正例 | 预测负例 |
| :------: | :------: | :------: |
| 真实正例 |    TP    |    FN    |
| 真实负例 |    FP    |    TN    |

准确率和召回率不可得兼。以准确率作为纵轴、召回率作为横轴，可以得到`P-R曲线`，曲线中“准确率=召回率”的点成为`平衡点`（Break-Even Point）。

准确率和召回率的`调和平均`（harmonic mean）成为`F1`度量：
$$
\begin{aligned}
\frac {1} {F1} &= \frac {1} {2} (\frac {1} {P} + \frac {1} {R}) \\
F1 &= \frac {2PR} {P + R}
\end{aligned}
$$
由多组混淆矩阵计算多组准确率和召回率，再求平均值，可得`宏准确率`（macro-P）和`宏召回率`（macro-R）；将多组混淆矩阵求平均值，再求准确率和召回率，可得`微准确率`（micro-P）和`微召回率`（micro-R）。

### 参考文献

1. 周志华. "机器学习." 清华大学出版社，北京.

