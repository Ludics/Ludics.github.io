# 《机器学习》西瓜书阅读笔记

## 第 1 章 绪论

### 基本术语

`机器学习`：在计算机上从`数据`（data）中产生`模型`（model）的算法，即`学习算法`（learning algorithm）。

A computer program is said to learn from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, if its performance at tasks in $T$, as measured by $P$, improves with experience $E$.

一般地，令 $D = \left \{ \mathbf{x_1}, \mathbf{x_2}, \cdots, \mathbf{x_m} \right \}$ 表示包含 $m$ 个`样本`（sample）的数据集，每个示例由 $d$ 个`属性`（attribute）描述，则每个样本 $\mathbf{x_i} = \left \{x_{i1}; x_{i2}; \cdots; x_{id} \right \}$ 是 $d$ 维样本空间 $\chi$ 中的一个向量，$\mathbf{x_i} \in \chi$，其中 $x_{ij}$ 是 $\mathbf{x_i}$ 在第 $j$ 个属性上的取值，$d$ 称为样本 $\mathbf{x_i}$ 的`维数`（dimensionality）。

属性张成的空间称为`样本空间`（sample space），每个样本都可在这个空间中找到唯一的坐标位置，因此也把一个样本称为一个`特征向量`（feature vector）。

从数据中学得模型的过程称之为`学习`（learning）或`训练`（training），学得模型适用于新样本的能力称为`泛化`（generalization）能力。

### 假设空间

`归纳`（induction）与`演绎`（deduction）是科学推理的两大基本手段。前者是从特殊到一般的泛化（generalization）过程，后者是从一般到特殊的特化（specialization）过程。从样例中学习是一个归纳的过程，亦称`归纳学习`（inductive learning）。

狭义的归纳学习是从数据中学得`概念`（concept），最基本的概念学习是布尔概念学习。可以把学习的过程看作一个在所有`假设`（hypothesis）组成的空间中进行搜索的过程，搜索目标是找到与训练集`匹配`（fit）的假设。

假设的表示一旦确定，`假设空间`（hypothesis space）及其规模大小就确定了。现实问题中通常面临很大的假设空间，但样本训练集是有限的，因此可能有多个假设与训练集一致，即存在一个与训练集一致的假设集合，称之为`版本空间`（version space）。

### 归纳偏好

机器学习算法在学习过程中对某种类型假设的偏好，称为`归纳偏好`（inductive bias）。归纳偏好可看作是学习算法在庞大的假设空间中对假设进行选择的价值观。

`奥卡姆剃刀`（Occam's Razor）是自然科学研究中常用的原则，即若存在多个假设与观察一致，则选最简单的那个。如无必要，勿增实体。

但奥卡姆剃刀原则并不平凡，“简单”的评价标准无法量化。事实上归纳偏好对应了学习算法本身所做出的关于“什么样的模型更好”的假设。`没有免费的午餐定理`（No Free Lunch Theorem，NFL）证明了在真实目标函数 $f$ 均匀分布的情况下，所有学习算法学得的模型期望性能是一致的。

脱离实际问题，空谈“什么学习算法更好”毫无意义。

### 参考文献

1. 周志华. "机器学习." 清华大学出版社，北京.

