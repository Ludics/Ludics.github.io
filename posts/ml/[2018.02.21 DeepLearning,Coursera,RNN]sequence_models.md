# Coursera: Sequence Models

### 1. Basic RNN

![](../images/ee3baa059d65f93c4b0e6468c950c761.png)
$$
a^{<t>} = g(W_{a} \begin{bmatrix} a^{<t-1>}\\ x^{<t>} \end{bmatrix} + b_a)
$$

$$
\hat y^{<t>} = g(W_{y} a^{<t>} + b_y)
$$

### 2. Language Model

* Input: $sentence$
* Output: $P(sentence)$
* Training set: large corpus of text
* $x^{<t>}$: $x^{<1>} = \vec 0, x^{<t>} = y^{<t - 1>}$
* $\hat y^{<t>}$: $P(word | y^{<1>}, \cdots, y^{<t - 1>})$
* Loss: $\mathcal L(\hat y^{<t>}, y^{<t>}) = - \sum_i {y_i^{<t>} \log \hat y^{<t>}}$

![](../images/b155aa7ae417f4238532bce795525df3.png)

Sampling a Sequence:

![](../images/8f9e5e5bc65cf25cef420bf73f62b531.png)

### 3. Gradient

* Exploding: gradient clipping
* Vanishing: GRU, LSTM

### 4. GRU & LSTM

[Learning]

### 5. Word Embeddings 

[Learning]

### 6. Beam Search

[Learning]

### 7. Attention

[Learning]

#### Reference

1. [Sequence Models on Coursera](https://www.coursera.org/learn/nlp-sequence-models)