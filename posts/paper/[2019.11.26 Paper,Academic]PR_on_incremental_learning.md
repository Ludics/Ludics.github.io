# Paper Reading on Incremental Learning

## 1. Memory Replay GANs: learning to generate images from new categories without forgetting

Wu, C., Herranz, L., Liu, X., Wang, Y., Van De Weijer, J., & Raducanu, B. (2018). Memory replay Gans: Learning to generate images from new categories without forgetting. Advances in Neural Information Processing Systems, 2018-December(NeurIPS), 5962–5972.

### 1.1 Abstract

> Previous works on sequential learning address the problem of forgetting in discriminative models. In this paper we consider the case of generative models. In particular, we investigate generative adversarial networks (GANs) in the task of learning new categories in a sequential fashion. We first show that sequential fine tuning renders the network unable to properly generate images from previous categories (i.e. forgetting). Addressing this problem, we propose Memory Replay GANs (MeRGANs), a conditional GAN framework that integrates a memory replay generator. We study two methods to prevent forgetting by leveraging these replays, namely joint training with replay and replay alignment. Qualitative and quantitative experimental results in MNIST, SVHN and LSUN datasets show that our memory replay approach can generate competitive images while significantly mitigating the forgetting of previous categories.

顺序学习的先前工作解决了判别模型中的遗忘问题。在本文中，我们考虑生成模型的情况。特别是，我们研究生成式对抗网络以顺序的方式学习新类别的任务。我们首先揭示顺序微调使网络无法正确地生成先前的类别图像（即，遗忘）。为了解决这个问题，我们提出了Memory Replay GANs（MeRGANs），它是一个有条件的GAN框架，它集成了一个记忆重播生成器。我们研究了两种利用重播来防止遗忘的方法，即带重播的联合训练和重播对齐。在 MNIST，SVHN 和 LSUN 数据集中的定性和定量实验结果表明，我们的内存重播方法可以生成有竞争力的图像，同时显着减轻了先前类别的遗忘。

### 1.2 Introduction

GAN: 从低维隐空间到感兴趣的复杂分布，如自然图像。生成器与判别器间的对抗游戏；新结构，新loss

语义属性难以控制；条件GAN 使用语义条件作为输入，语义属性与固有多样性解藕。最简单的条件为类别标签，可以控制生成图像的标签。常规设置下，图像生成模型假设所有的训练数据在训练时可用。实践中这样的假设可能难以满足。现代神经网络要面对任务与数据预先不可知，需要在有新数据或任务时连续地更新模型。然而如果用顺序的方式更新神经网络，而不去重新访问之前的数据，神经网络会出现严重的退化，称为灾难性遗忘。防止遗忘的策略有对权重或激活层正则化、保留一小类的先前样本，或者记忆重播机制。

本文聚焦于生成模型尤其是GAN中的遗忘，通过生成类别以顺序方式展现且不交叉的图像。有文章使用elastic weight，与本文较为相似。不过我们依赖于记忆重播，并介绍了两种方法，分别是联合重训练和对齐重播。前者在训练过程中包括重播的样本，后者强制将当前生成器的重放与辅助生成器生成的重放同步。所谓辅助生成器，是指学习新任务前保留的快照。

### 1.3 在GAN中顺序学习

先介绍非顺序设置下的条件GAN。
